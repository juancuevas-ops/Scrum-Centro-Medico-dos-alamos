{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regresion_multilineal_juancuevas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHnq4N7583jURinxDV0dVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juancuevas-ops/Scrum-Centro-Medico-dos-alamos/blob/main/regresion_multilineal_juancuevas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljl9XgQHivJb"
      },
      "source": [
        "#Se importan la librerias a utilizar\n",
        "from sklearn import datasets, linear_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VipQ22xojD_K"
      },
      "source": [
        "#Importamos los datos de la misma librer√≠a de scikit-learn\n",
        "forever_lineal = datasets.load_boston()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X98hdmgDjGUG",
        "outputId": "77e51178-b836-451c-b642-a760a909c9be"
      },
      "source": [
        "forever_lineal"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
              " 'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "         4.9800e+00],\n",
              "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "         9.1400e+00],\n",
              "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "         4.0300e+00],\n",
              "        ...,\n",
              "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         5.6400e+00],\n",
              "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "         6.4800e+00],\n",
              "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         7.8800e+00]]),\n",
              " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
              " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/boston_house_prices.csv',\n",
              " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq5y_xQUjS1G",
        "outputId": "77397d74-1943-4f7b-9267-8a546c9774c1"
      },
      "source": [
        "#Verifico la informaci√≥n contenida en el dataset\n",
        "print('Informaci√≥n en el dataset:')\n",
        "print(forever_lineal.keys())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Informaci√≥n en el dataset:\n",
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1H4xZXTjcqm",
        "outputId": "262e2bb8-a30e-473e-d8c6-c13462bebee9"
      },
      "source": [
        "#Verifico las caracter√≠sticas del dataset\n",
        "print('Caracter√≠sticas del dataset:')\n",
        "print(forever_lineal.DESCR)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caracter√≠sticas del dataset:\n",
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FI3zzZoj9hk"
      },
      "source": [
        "Como podemos leer en la descripci√≥n este dataset cuenta con 506 datos y 13 atributos, la columna 14 es el target y es la media del valor de las viviendas.\n",
        "\n",
        "Seguidamente tenemos la descripci√≥n del significado de cada una de las columnas o atributos de los datos. De igual forma nos indica un dato importante para nuestro an√°lisis y es que nos indican que no existe ning√∫n valor perdido, en consecuencia, nuestra data esta completa por lo que no es necesario realizar mucho preprocesamiento a los datos.\n",
        "\n",
        "Ahora utilizaremos la instrucci√≥n shape para determinar la cantidad de datos contamos, aunque este es un paso de m√°s ya que esta informaci√≥n nos la hab√≠a dado previamente la descripci√≥n del dataset, pero de todas formas lo hacemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5WSGlMej8dr",
        "outputId": "a2f264ff-0292-4a0e-9614-8d40c86d8832"
      },
      "source": [
        "#Verifico la cantidad de datos que hay en los dataset\n",
        "print('Cantidad de datos:')\n",
        "print(forever_lineal.data.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de datos:\n",
            "(506, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BdeXIWkX7s"
      },
      "source": [
        "Como ya nos lo hab√≠an indicado este conjunto de datos cuenta con 506 muestras y 13 columnas.\n",
        "\n",
        "Finalmente veamos las etiquetas de cada columna para ello utilizamos feature_names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJzgwhykZCy",
        "outputId": "c0117ad9-e416-4435-a7b5-8cc133c5cbba"
      },
      "source": [
        "#Verifico la informaci√≥n de las columnas\n",
        "print('Nombres columnas:')\n",
        "print(forever_lineal.feature_names)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombres columnas:\n",
            "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LH5CyTrksDK"
      },
      "source": [
        "Sabiendo toda esta informaci√≥n entonces procedemos a preparar los datos que vamos a utilizar para crear el modelo.\n",
        "\n",
        "Para este ejemplo vamos a implementar un predictor de Regresi√≥n Lineal M√∫ltiple, por lo que podemos tomar varios atributos de nuestros datos para crear el modelo. Para nuestro an√°lisis solamente vamos a tomar las columnas correspondientes al n√∫mero de habitaciones con las que cuenta la casa, esta ser√≠a la que lleva por nombre ‚ÄúRM‚Äù, el tiempo que ha tenido ocupada, correspondiente a la columna ‚ÄúAGE‚Äù y la distancia que se encuentra la misma de los centros de trabajos de Boston que vendr√≠a siendo la columna con el nombre ‚ÄúDIS‚Äù. Estas columnas se encuentran ubicadas en la posici√≥n 5, 6 y 7 de los datos y estas vendr√≠an siendo la variable ‚ÄúX‚Äù."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "temAhzXgknjq"
      },
      "source": [
        "#Seleccionamos las columna 5, 6 y 7 del dataset\n",
        "X_multiple = forever_lineal.data[:, 5:8]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz9kG2NilEgo"
      },
      "source": [
        "Definido ‚ÄúX‚Äù ahora definimos ‚Äúy‚Äù el cual ser√° igual a los datos contenidos en target, como ya lo hab√≠amos visto anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PheKkDXvlFto"
      },
      "source": [
        "#Defino los datos correspondientes a las etiquetas\n",
        "y_multiple = forever_lineal.target"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdK6T18UlTZv"
      },
      "source": [
        "Como ya tenemos nuestros datos ahora procedemos a separarlos en entrenamiento y prueba lo hacemos utilizando la instrucci√≥n train_test_split, no si antes importando la respectiva librer√≠a.\n",
        "\n",
        "Para la separaci√≥n de los datos, vamos a tomar un 20% de los mismos para utilizarlos como prueba una vez que hayamos obtenido el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23WNncKlUzf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multiple, y_multiple, test_size=0.2)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7_Jb4GKl0sN"
      },
      "source": [
        "Seguidamente definimos el algoritmo a utilizar que es el de LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fkCHzrl2Tt"
      },
      "source": [
        "#Defino el algoritmo a utilizar\n",
        "lr_multiple = linear_model.LinearRegression()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOFa2TvKmMMs"
      },
      "source": [
        "F√≠jate que es el mismo algoritmo que utilizamos en el ejemplo de Regresi√≥n Lineal Simple, esto se debe a que todos los algoritmos relacionados a Regresi√≥n Lineal utilizan esta misma librer√≠a, es decir no tiene que configurarse nada adicional para implementarla.\n",
        "\n",
        "Definido el algoritmo ahora procedemos a entrenar nuestro modelo con los datos correspondiente, para ello utilizamos la instrucci√≥n fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBsj3XuhmH7N",
        "outputId": "6e4d0600-b7f9-43ea-c0c3-eb610fd16af2"
      },
      "source": [
        "#Entreno el modelo\n",
        "lr_multiple.fit(X_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZafk1YGmjqL"
      },
      "source": [
        "Y finalmente realizamos la predicci√≥n utilizando los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBhVEHbZmk58"
      },
      "source": [
        "#Realizo una predicci√≥n\n",
        "Y_pred_multiple = lr_multiple.predict(X_test)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkDJh23Xmyaq",
        "outputId": "9aa56482-e9ad-4545-b682-bd6550fb3e76"
      },
      "source": [
        "print(Y_pred_multiple)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31.02059098 20.78861774 15.36265058 19.66525735 27.999917   19.84924273\n",
            " 15.48821449 15.37818757 19.11178944 20.30402786 32.34663612 21.04095236\n",
            " 38.65555818 31.72357692 24.01084832 21.72562544 31.66691093 26.78222037\n",
            " 21.51087883 34.11035655 21.3360692  21.69325642 14.25177584 36.89037273\n",
            " 23.85651485 26.39684311 38.1359433  18.11014856 14.59672685 31.88847266\n",
            " 23.58718308 20.67447625 31.59635275 22.19271749 24.2592944  19.45553398\n",
            " 28.60552632 28.40772788 21.76347491 37.21289281 38.39823023 22.01649258\n",
            " 22.89792204 22.48200933 14.10693315 37.22902127 26.13458075 21.7622013\n",
            " 20.25618082 25.96764382 17.26019026 23.45574795 32.18072822 11.43728333\n",
            " 34.28184305 26.22004985 15.65497461 19.50048751 23.19084554 35.82963798\n",
            " 15.42106288 21.28757022 18.95630526 25.89864989 21.6193571  30.3100095\n",
            " 13.53191383 19.68971892 24.30180469 23.26821354 18.18380512 20.63626298\n",
            " 21.65005716 27.12929297 30.15467617 28.970126   26.18087932 20.0035157\n",
            " 37.20232773 17.56639143 21.98311534 16.37953731 15.62852252 28.12617407\n",
            " 25.1254645  30.15807186 28.13477605 18.79362876 25.77859521 22.10262945\n",
            " 26.29371901 26.18740401 21.39569026 17.26469344 23.57307239 24.07467303\n",
            " 29.51586787 19.87399547 20.74972745 24.86065907 20.00835382 13.95019574]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvP3XkQznhQV",
        "outputId": "5de3518c-653e-43f0-b341-327666cf421c"
      },
      "source": [
        "print('DATOS DEL MODELO REGRESI√ìN LINEAL MULTIPLE')\n",
        "print()\n",
        "print('Valor de las pendientes o coeficientes \"a\":')\n",
        "print(lr_multiple.coef_)\n",
        "print('Valor de la intersecci√≥n o coeficiente \"b\":')\n",
        "print(lr_multiple.intercept_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATOS DEL MODELO REGRESI√ìN LINEAL MULTIPLE\n",
            "\n",
            "Valor de las pendientes o coeficientes \"a\":\n",
            "[ 8.12143375 -0.10909645 -0.56852593]\n",
            "Valor de la intersecci√≥n o coeficiente \"b\":\n",
            "-18.866592850498115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJMRaGNhnqk7"
      },
      "source": [
        "Como podemos observar para ‚Äúa‚Äù, nos devuelve tres valores, esto se debe a que estamos utilizando 3 caracter√≠sticas para nuestro an√°lisis por lo que cada una de ellas tendr√° un valor correspondiente de ‚Äúa‚Äù. Los valores ser√≠an los siguientes: 8,215 para el primero, -0,096 para el segundo y -0,491 para el √∫ltimo. A su vez el valor de ‚Äúb‚Äù o la intersecci√≥n es de -20,354.\n",
        "\n",
        "Teniendo todos estos datos ahora calculemos la precisi√≥n del algoritmo para ello empleamos la instrucci√≥n ‚Äúscore‚Äù el cual devuelve el resultado de la estad√≠stica R al cuadrado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avmndf2znr0w",
        "outputId": "5417a940-413b-4652-e0fb-f3d5a81f8cd3"
      },
      "source": [
        "print('Precisi√≥n del modelo:')\n",
        "print(lr_multiple.score(X_train, y_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisi√≥n del modelo:\n",
            "0.47609919319117655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw86dTHXn_jn"
      },
      "source": [
        "El resultado obtenido ac√° es de 0,518, como ya lo hab√≠amos visto comparando los resultados de ‚Äúy_predict‚Äù pod√≠amos deducir que la precisi√≥n no iba a ser muy buena. Recuerda que mientras este valor sea m√°s cercano a 1 mejor ser√° nuestro modelo.\n",
        "\n",
        "Finalizando ya nuestro an√°lisis podemos decir que el programa en si es muy parecido al de Regresi√≥n Lineal Simple, por no decir que igual, la √∫nica gran diferencia es que los datos de X contendr√°n m√°s de una columna o caracter√≠stica de nuestro datase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "VkMACWAcoAlw",
        "outputId": "a931cd7d-1f1f-4439-81ea-fc0c54a37b35"
      },
      "source": [
        "import numpy as np #Librer√≠a num√©rica\n",
        "import matplotlib.pyplot as plt # Para crear gr√°ficos con matplotlib\n",
        "%matplotlib inline \n",
        "from sklearn.linear_model import LinearRegression #Regresi√≥n Lineal con scikit-learn\n",
        "def f(x):  # funci√≥n f(x) = 0.1*x + 1.25 + 0.2*Ruido_Gaussiano\n",
        "    np.random.seed(506) # para poder reproducirlo\n",
        "    y = 0.1*x + 1.26 + 0.2*np.random.randn(x.shape[0])\n",
        "    return y\n",
        "x = np.arange(0, 20, 0.5) # generamos valores x de 0 a 20 en intervalos de 0.5\n",
        "y = f(x) # calculamos y a partir de la funci√≥n que hemos generado\n",
        "# hacemos un gr√°fico de los datos que hemos generado\n",
        "plt.scatter(x,y,label='data', color='blue')\n",
        "plt.title('Datos');"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}