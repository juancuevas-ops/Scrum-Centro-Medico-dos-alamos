{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regresion_multilineal_juancuevas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHnq4N7583jURinxDV0dVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juancuevas-ops/Scrum-Centro-Medico-dos-alamos/blob/main/regresion_multilineal_juancuevas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljl9XgQHivJb"
      },
      "source": [
        "#Se importan la librerias a utilizar\n",
        "from sklearn import datasets, linear_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VipQ22xojD_K"
      },
      "source": [
        "#Importamos los datos de la misma librería de scikit-learn\n",
        "forever_lineal = datasets.load_boston()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X98hdmgDjGUG",
        "outputId": "77e51178-b836-451c-b642-a760a909c9be"
      },
      "source": [
        "forever_lineal"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
              " 'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "         4.9800e+00],\n",
              "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "         9.1400e+00],\n",
              "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "         4.0300e+00],\n",
              "        ...,\n",
              "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         5.6400e+00],\n",
              "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "         6.4800e+00],\n",
              "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         7.8800e+00]]),\n",
              " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
              " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/boston_house_prices.csv',\n",
              " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq5y_xQUjS1G",
        "outputId": "77397d74-1943-4f7b-9267-8a546c9774c1"
      },
      "source": [
        "#Verifico la información contenida en el dataset\n",
        "print('Información en el dataset:')\n",
        "print(forever_lineal.keys())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Información en el dataset:\n",
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1H4xZXTjcqm",
        "outputId": "262e2bb8-a30e-473e-d8c6-c13462bebee9"
      },
      "source": [
        "#Verifico las características del dataset\n",
        "print('Características del dataset:')\n",
        "print(forever_lineal.DESCR)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Características del dataset:\n",
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FI3zzZoj9hk"
      },
      "source": [
        "Como podemos leer en la descripción este dataset cuenta con 506 datos y 13 atributos, la columna 14 es el target y es la media del valor de las viviendas.\n",
        "\n",
        "Seguidamente tenemos la descripción del significado de cada una de las columnas o atributos de los datos. De igual forma nos indica un dato importante para nuestro análisis y es que nos indican que no existe ningún valor perdido, en consecuencia, nuestra data esta completa por lo que no es necesario realizar mucho preprocesamiento a los datos.\n",
        "\n",
        "Ahora utilizaremos la instrucción shape para determinar la cantidad de datos contamos, aunque este es un paso de más ya que esta información nos la había dado previamente la descripción del dataset, pero de todas formas lo hacemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5WSGlMej8dr",
        "outputId": "a2f264ff-0292-4a0e-9614-8d40c86d8832"
      },
      "source": [
        "#Verifico la cantidad de datos que hay en los dataset\n",
        "print('Cantidad de datos:')\n",
        "print(forever_lineal.data.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de datos:\n",
            "(506, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BdeXIWkX7s"
      },
      "source": [
        "Como ya nos lo habían indicado este conjunto de datos cuenta con 506 muestras y 13 columnas.\n",
        "\n",
        "Finalmente veamos las etiquetas de cada columna para ello utilizamos feature_names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJzgwhykZCy",
        "outputId": "c0117ad9-e416-4435-a7b5-8cc133c5cbba"
      },
      "source": [
        "#Verifico la información de las columnas\n",
        "print('Nombres columnas:')\n",
        "print(forever_lineal.feature_names)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombres columnas:\n",
            "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LH5CyTrksDK"
      },
      "source": [
        "Sabiendo toda esta información entonces procedemos a preparar los datos que vamos a utilizar para crear el modelo.\n",
        "\n",
        "Para este ejemplo vamos a implementar un predictor de Regresión Lineal Múltiple, por lo que podemos tomar varios atributos de nuestros datos para crear el modelo. Para nuestro análisis solamente vamos a tomar las columnas correspondientes al número de habitaciones con las que cuenta la casa, esta sería la que lleva por nombre “RM”, el tiempo que ha tenido ocupada, correspondiente a la columna “AGE” y la distancia que se encuentra la misma de los centros de trabajos de Boston que vendría siendo la columna con el nombre “DIS”. Estas columnas se encuentran ubicadas en la posición 5, 6 y 7 de los datos y estas vendrían siendo la variable “X”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "temAhzXgknjq"
      },
      "source": [
        "#Seleccionamos las columna 5, 6 y 7 del dataset\n",
        "X_multiple = forever_lineal.data[:, 5:8]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz9kG2NilEgo"
      },
      "source": [
        "Definido “X” ahora definimos “y” el cual será igual a los datos contenidos en target, como ya lo habíamos visto anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PheKkDXvlFto"
      },
      "source": [
        "#Defino los datos correspondientes a las etiquetas\n",
        "y_multiple = forever_lineal.target"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdK6T18UlTZv"
      },
      "source": [
        "Como ya tenemos nuestros datos ahora procedemos a separarlos en entrenamiento y prueba lo hacemos utilizando la instrucción train_test_split, no si antes importando la respectiva librería.\n",
        "\n",
        "Para la separación de los datos, vamos a tomar un 20% de los mismos para utilizarlos como prueba una vez que hayamos obtenido el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23WNncKlUzf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multiple, y_multiple, test_size=0.2)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7_Jb4GKl0sN"
      },
      "source": [
        "Seguidamente definimos el algoritmo a utilizar que es el de LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fkCHzrl2Tt"
      },
      "source": [
        "#Defino el algoritmo a utilizar\n",
        "lr_multiple = linear_model.LinearRegression()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOFa2TvKmMMs"
      },
      "source": [
        "Fíjate que es el mismo algoritmo que utilizamos en el ejemplo de Regresión Lineal Simple, esto se debe a que todos los algoritmos relacionados a Regresión Lineal utilizan esta misma librería, es decir no tiene que configurarse nada adicional para implementarla.\n",
        "\n",
        "Definido el algoritmo ahora procedemos a entrenar nuestro modelo con los datos correspondiente, para ello utilizamos la instrucción fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBsj3XuhmH7N",
        "outputId": "6e4d0600-b7f9-43ea-c0c3-eb610fd16af2"
      },
      "source": [
        "#Entreno el modelo\n",
        "lr_multiple.fit(X_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZafk1YGmjqL"
      },
      "source": [
        "Y finalmente realizamos la predicción utilizando los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBhVEHbZmk58"
      },
      "source": [
        "#Realizo una predicción\n",
        "Y_pred_multiple = lr_multiple.predict(X_test)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkDJh23Xmyaq",
        "outputId": "9aa56482-e9ad-4545-b682-bd6550fb3e76"
      },
      "source": [
        "print(Y_pred_multiple)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31.02059098 20.78861774 15.36265058 19.66525735 27.999917   19.84924273\n",
            " 15.48821449 15.37818757 19.11178944 20.30402786 32.34663612 21.04095236\n",
            " 38.65555818 31.72357692 24.01084832 21.72562544 31.66691093 26.78222037\n",
            " 21.51087883 34.11035655 21.3360692  21.69325642 14.25177584 36.89037273\n",
            " 23.85651485 26.39684311 38.1359433  18.11014856 14.59672685 31.88847266\n",
            " 23.58718308 20.67447625 31.59635275 22.19271749 24.2592944  19.45553398\n",
            " 28.60552632 28.40772788 21.76347491 37.21289281 38.39823023 22.01649258\n",
            " 22.89792204 22.48200933 14.10693315 37.22902127 26.13458075 21.7622013\n",
            " 20.25618082 25.96764382 17.26019026 23.45574795 32.18072822 11.43728333\n",
            " 34.28184305 26.22004985 15.65497461 19.50048751 23.19084554 35.82963798\n",
            " 15.42106288 21.28757022 18.95630526 25.89864989 21.6193571  30.3100095\n",
            " 13.53191383 19.68971892 24.30180469 23.26821354 18.18380512 20.63626298\n",
            " 21.65005716 27.12929297 30.15467617 28.970126   26.18087932 20.0035157\n",
            " 37.20232773 17.56639143 21.98311534 16.37953731 15.62852252 28.12617407\n",
            " 25.1254645  30.15807186 28.13477605 18.79362876 25.77859521 22.10262945\n",
            " 26.29371901 26.18740401 21.39569026 17.26469344 23.57307239 24.07467303\n",
            " 29.51586787 19.87399547 20.74972745 24.86065907 20.00835382 13.95019574]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvP3XkQznhQV",
        "outputId": "5de3518c-653e-43f0-b341-327666cf421c"
      },
      "source": [
        "print('DATOS DEL MODELO REGRESIÓN LINEAL MULTIPLE')\n",
        "print()\n",
        "print('Valor de las pendientes o coeficientes \"a\":')\n",
        "print(lr_multiple.coef_)\n",
        "print('Valor de la intersección o coeficiente \"b\":')\n",
        "print(lr_multiple.intercept_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATOS DEL MODELO REGRESIÓN LINEAL MULTIPLE\n",
            "\n",
            "Valor de las pendientes o coeficientes \"a\":\n",
            "[ 8.12143375 -0.10909645 -0.56852593]\n",
            "Valor de la intersección o coeficiente \"b\":\n",
            "-18.866592850498115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJMRaGNhnqk7"
      },
      "source": [
        "Como podemos observar para “a”, nos devuelve tres valores, esto se debe a que estamos utilizando 3 características para nuestro análisis por lo que cada una de ellas tendrá un valor correspondiente de “a”. Los valores serían los siguientes: 8,215 para el primero, -0,096 para el segundo y -0,491 para el último. A su vez el valor de “b” o la intersección es de -20,354.\n",
        "\n",
        "Teniendo todos estos datos ahora calculemos la precisión del algoritmo para ello empleamos la instrucción “score” el cual devuelve el resultado de la estadística R al cuadrado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avmndf2znr0w",
        "outputId": "5417a940-413b-4652-e0fb-f3d5a81f8cd3"
      },
      "source": [
        "print('Precisión del modelo:')\n",
        "print(lr_multiple.score(X_train, y_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión del modelo:\n",
            "0.47609919319117655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw86dTHXn_jn"
      },
      "source": [
        "El resultado obtenido acá es de 0,518, como ya lo habíamos visto comparando los resultados de “y_predict” podíamos deducir que la precisión no iba a ser muy buena. Recuerda que mientras este valor sea más cercano a 1 mejor será nuestro modelo.\n",
        "\n",
        "Finalizando ya nuestro análisis podemos decir que el programa en si es muy parecido al de Regresión Lineal Simple, por no decir que igual, la única gran diferencia es que los datos de X contendrán más de una columna o característica de nuestro datase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "VkMACWAcoAlw",
        "outputId": "a931cd7d-1f1f-4439-81ea-fc0c54a37b35"
      },
      "source": [
        "import numpy as np #Librería numérica\n",
        "import matplotlib.pyplot as plt # Para crear gráficos con matplotlib\n",
        "%matplotlib inline \n",
        "from sklearn.linear_model import LinearRegression #Regresión Lineal con scikit-learn\n",
        "def f(x):  # función f(x) = 0.1*x + 1.25 + 0.2*Ruido_Gaussiano\n",
        "    np.random.seed(506) # para poder reproducirlo\n",
        "    y = 0.1*x + 1.26 + 0.2*np.random.randn(x.shape[0])\n",
        "    return y\n",
        "x = np.arange(0, 20, 0.5) # generamos valores x de 0 a 20 en intervalos de 0.5\n",
        "y = f(x) # calculamos y a partir de la función que hemos generado\n",
        "# hacemos un gráfico de los datos que hemos generado\n",
        "plt.scatter(x,y,label='data', color='blue')\n",
        "plt.title('Datos');"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}